# Gemini API Configuration
GEMINI_API_KEY=your_gemini_api_key_here
GEMINI_MODEL=gemini-2.5-flash

# Context Management Configuration
DEFAULT_COMPRESSION_THRESHOLD=5000
MAX_INPUT_TOKENS=1048576
MAX_OUTPUT_TOKENS=65535

# Student Summarizer Configuration (Optional lightweight model)
STUDENT_SUMMARIZER_MODEL=gemini-1.5-flash-8b
STUDENT_SUMMARIZER_MAX_TOKENS=2000

# Compression Strategy Settings
# Valid strategies: semantic_pruning, knowledge_distillation, history_compaction, none
# Use JSON array format for multiple strategies:
# COMPRESSION_STRATEGIES=["semantic_pruning", "knowledge_distillation", "history_compaction"]
COMPRESSION_STRATEGIES=["semantic_pruning", "knowledge_distillation", "history_compaction"]

# Legacy boolean flags (deprecated, use COMPRESSION_STRATEGIES instead)
ENABLE_SEMANTIC_PRUNING=true
ENABLE_KNOWLEDGE_DISTILLATION=true
ENABLE_HISTORY_COMPACTION=true
COMPRESSION_COST_MULTIPLIER=1.5

# Output Serialization Settings
# Valid formats: toon, compact_json, json
DEFAULT_OUTPUT_FORMAT=toon
TOON_FALLBACK_THRESHOLD=0.3
ENABLE_FORMAT_NEGOTIATION=true

# Monitoring and Logging
# Valid log levels: DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_LEVEL=INFO
ENABLE_METRICS_LOGGING=true
METRICS_LOG_FILE=./logs/metrics.jsonl

# Multi-Cloud Settings (Optional)
ENABLE_LITELLM=false
LITELLM_FALLBACK_MODELS=gpt-4,claude-3-sonnet
